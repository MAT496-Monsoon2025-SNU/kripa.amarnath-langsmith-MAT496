{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4099a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running comparative evaluation...\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/7078c9e6-ede7-4d80-b45b-119f20137777/datasets/80f6d3d0-3e0a-404f-8845-b073c7c16f44/compare?selectedSessions=20fa3c52-fd37-4437-b2d3-7b83e0411705%2C2c241beb-3b6e-4145-8400-8d2cdc405068&comparativeExperiment=0fb26c92-c037-4ef4-a2aa-1aa0eacdcc29\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4be4b216ff4af9840dff283f3610a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating stories for prompt: A lone astronaut discovers a strange, glowing plan...\n",
      "Evaluating stories for prompt: A talking cat helps a shy librarian uncover a magi...\n",
      "Evaluating stories for prompt: In a future where dreams can be recorded, a detect...\n",
      "Evaluating stories for prompt: A baker finds a mysterious ingredient that makes h...\n",
      "Evaluating stories for prompt: Two rival knights from different kingdoms meet by ...\n",
      "Comparative evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langsmith import evaluate\n",
    "\n",
    "character_driven_experiment_id = \"20fa3c52-fd37-4437-b2d3-7b83e0411705\"\n",
    "plot_driven_experiment_id = \"2c241beb-3b6e-4145-8400-8d2cdc405068\"\n",
    "\n",
    "print(\"Running comparative evaluation...\")\n",
    "evaluate(\n",
    "    [character_driven_experiment_id, plot_driven_experiment_id],\n",
    "    evaluators=[ranked_preference]\n",
    ")\n",
    "print(\"Comparative evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6818032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from groq import Groq\n",
    "import uuid \n",
    "\n",
    "\n",
    "def ranked_preference(runs, example):\n",
    "    \"\"\"\n",
    "    Evaluates two runs (stories) against an example prompt using a Groq model as a judge.\n",
    "    Returns a dictionary in the format expected by LangSmith for comparative evaluation.\n",
    "    \"\"\"\n",
    "    if len(runs) != 2:\n",
    "        raise ValueError(\"This evaluator expects exactly two runs for comparison.\")\n",
    "\n",
    "    prompt_text = example.inputs.get(\"prompt\", \"No prompt provided in example.\")\n",
    "\n",
    "    \n",
    "    story_a = runs[0].outputs.get(\"output\", \"N/A\") if runs[0].outputs else \"N/A\"\n",
    "    story_b = runs[1].outputs.get(\"output\", \"N/A\") if runs[1].outputs else \"N/A\"\n",
    "\n",
    "   \n",
    "    run_id_a = str(runs[0].id)\n",
    "    run_id_b = str(runs[1].id)\n",
    "\n",
    "    print(f\"Evaluating stories for prompt: {prompt_text[:50]}...\")\n",
    "\n",
    "    try:\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=GROQ_MODEL,\n",
    "            messages=[\n",
    "                {   \n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": JUDGE_SYSTEM_PROMPT,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": JUDGE_HUMAN_PROMPT.format(\n",
    "                        prompt=prompt_text, \n",
    "                        story_a=story_a,\n",
    "                        story_b=story_b\n",
    "                    )}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0.0,\n",
    "            max_tokens=50,\n",
    "        )\n",
    "        \n",
    "        parsed_content = json.loads(completion.choices[0].message.content)\n",
    "        preference_score = parsed_content.get(\"preference\")\n",
    "\n",
    "        if preference_score not in [\"A\", \"B\", \"Tie\"]:\n",
    "            print(f\"Warning: Unexpected preference score received: {preference_score}. Full response: {completion.choices[0].message.content}\")\n",
    "            return {\n",
    "                \"key\": \"ranked_preference\", \n",
    "                \"score\": 0, \n",
    "                \"comment\": f\"Invalid preference from judge: {preference_score}\",\n",
    "                \"scores\": {run_id_a: 0, run_id_b: 0} \n",
    "            }\n",
    "\n",
    "        scores_dict = {run_id_a: 0, run_id_b: 0} \n",
    "\n",
    "        if preference_score == \"A\":\n",
    "            scores_dict[run_id_a] = 1 \n",
    "            scores_dict[run_id_b] = 0\n",
    "        elif preference_score == \"B\":\n",
    "            scores_dict[run_id_a] = 0\n",
    "            scores_dict[run_id_b] = 1 \n",
    "        else: \n",
    "            scores_dict[run_id_a] = 0.5 \n",
    "            scores_dict[run_id_b] = 0.5\n",
    "            \n",
    "        return {\n",
    "            \"key\": \"ranked_preference\", \n",
    "            \"score\": preference_score, \n",
    "            \"comment\": f\"Judge preferred {preference_score}\",\n",
    "            \"scores\": scores_dict \n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Groq API call or JSON parsing: {e}\")\n",
    "        return {\n",
    "            \"key\": \"ranked_preference\",\n",
    "            \"score\": \"Error\",\n",
    "            \"comment\": f\"Evaluation failed: {e}\",\n",
    "            \"scores\": {run_id_a: 0, run_id_b: 0} \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3595813",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_SYSTEM_PROMPT = \"\"\"\n",
    "Please act as an impartial literary judge and evaluate the creativity and originality of two short stories generated from the same prompt.\n",
    "Your evaluation should consider factors such as narrative originality, imaginative details, character uniqueness, and the overall 'spark' of creativity. \n",
    "Begin your evaluation by comparing the two stories and provide a short explanation of your preference. \n",
    "Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. \n",
    "Do not favor certain names of the assistants. \n",
    "Be as objective as possible. \"\"\"\n",
    "\n",
    "JUDGE_HUMAN_PROMPT = \"\"\"\n",
    "[The Story Prompt] {prompt}\n",
    "\n",
    "[The Start of Assistant A's Story] {story_a} [The End of Assistant A's Story]\n",
    "\n",
    "[The Start of Assistant B's Story] {story_b} [The End of Assistant B's Story]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f6b5271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Character-Driven Story-d847abf9' at:\n",
      "https://smith.langchain.com/o/7078c9e6-ede7-4d80-b45b-119f20137777/datasets/80f6d3d0-3e0a-404f-8845-b073c7c16f44/compare?selectedSessions=20fa3c52-fd37-4437-b2d3-7b83e0411705\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349cea4f91ce4f3b9c0becc0ced435c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run d1a814fa-6a2b-4fd6-95bc-8819e3e3c010: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run f59c6f6b-4da7-4ae7-8913-1524b9ec70c2: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run 2b72d428-a813-4bec-a931-74cc634f65f0: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run 702cc4d7-b014-4546-8dd4-01c85fbe0111: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run 86d73d13-a43d-4540-a592-5df2a1779319: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.prompt</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>feedback.wrapper</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two rival knights from different kingdoms meet...</td>\n",
       "      <td>Sir Kaelen's visor gaped at the roiling, green...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.610456</td>\n",
       "      <td>58544518-82cc-452e-bd5a-55cb9a938c2d</td>\n",
       "      <td>d1a814fa-6a2b-4fd6-95bc-8819e3e3c010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A baker finds a mysterious ingredient that mak...</td>\n",
       "      <td>Elara, always practical, scoffed at the irides...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>b520ab2a-5837-4637-98eb-eb526a9ea313</td>\n",
       "      <td>f59c6f6b-4da7-4ae7-8913-1524b9ec70c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a future where dreams can be recorded, a de...</td>\n",
       "      <td>Rain lashed against Inspector Crowe's office w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.548364</td>\n",
       "      <td>36da89f4-36e0-4339-ab0c-b5d13d66ae83</td>\n",
       "      <td>2b72d428-a813-4bec-a931-74cc634f65f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A talking cat helps a shy librarian uncover a ...</td>\n",
       "      <td>Eleanor, the librarian, trembled as she held t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.651115</td>\n",
       "      <td>63c4dad9-5528-460f-bfe5-43c1ac42e94d</td>\n",
       "      <td>702cc4d7-b014-4546-8dd4-01c85fbe0111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A lone astronaut discovers a strange, glowing ...</td>\n",
       "      <td>Dr. Elara Vance's helmet visor reflected the d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.525727</td>\n",
       "      <td>cfde001b-7710-47c8-b1b6-b27e4e9d66ed</td>\n",
       "      <td>86d73d13-a43d-4540-a592-5df2a1779319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults Character-Driven Story-d847abf9>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def character_driven_story_generator(inputs: dict):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=GROQ_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Craft a unique, character-driven short story (around 100 words) inspired by this prompt: '{inputs['prompt']}'. Emphasize character development and introduce an unexpected element.\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "client.evaluate(\n",
    "    character_driven_story_generator,\n",
    "    data=dataset,\n",
    "    evaluators=[creativity_score_evaluator],\n",
    "    experiment_prefix=\"Character-Driven Story\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82254b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Plot-Driven Story-e726a52b' at:\n",
      "https://smith.langchain.com/o/7078c9e6-ede7-4d80-b45b-119f20137777/datasets/80f6d3d0-3e0a-404f-8845-b073c7c16f44/compare?selectedSessions=2c241beb-3b6e-4145-8400-8d2cdc405068\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300d6395ff174153893c4a9ad601d702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run dbc0f8de-6a2f-46bb-9511-fdedc1b4b7a5: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run 8571ed30-341b-4f50-a8c3-0eed3ed4e6b1: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run db10fcbf-be5a-4e57-b7d9-65d17583744a: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run ec9de22a-f810-4fe5-865d-4f4c5f044ac1: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n",
      "Error running evaluator <DynamicRunEvaluator creativity_score_evaluator> on run af733901-045e-436d-b035-4339ecd5d397: BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"\\'messages\\' must contain the word \\'json\\' in some form, to use \\'response_format\\' of type \\'json_object\\'.\", \\'type\\': \\'invalid_request_error\\'}}')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "        run=run,\n",
      "        example=example,\n",
      "        evaluator_run_id=evaluator_run_id,\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "        run,\n",
      "        example,\n",
      "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 693, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "        func, *args, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25208\\1564043241.py\", line 20, in creativity_score_evaluator\n",
      "    completion = groq_client.chat.completions.create(\n",
      "        model=GROQ_MODEL,\n",
      "    ...<12 lines>...\n",
      "        response_format={\"type\": \"json_object\"},\n",
      "    )\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 448, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\envs\\MAT496\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.prompt</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>feedback.wrapper</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two rival knights from different kingdoms meet...</td>\n",
       "      <td>The crimson halo bathed the battlefield in an ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.712201</td>\n",
       "      <td>58544518-82cc-452e-bd5a-55cb9a938c2d</td>\n",
       "      <td>dbc0f8de-6a2f-46bb-9511-fdedc1b4b7a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A baker finds a mysterious ingredient that mak...</td>\n",
       "      <td>Elara discovered a vial tucked in her grandmot...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.566061</td>\n",
       "      <td>b520ab2a-5837-4637-98eb-eb526a9ea313</td>\n",
       "      <td>8571ed30-341b-4f50-a8c3-0eed3ed4e6b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a future where dreams can be recorded, a de...</td>\n",
       "      <td>The holo-projection flickered, displaying a lu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.562653</td>\n",
       "      <td>36da89f4-36e0-4339-ab0c-b5d13d66ae83</td>\n",
       "      <td>db10fcbf-be5a-4e57-b7d9-65d17583744a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A talking cat helps a shy librarian uncover a ...</td>\n",
       "      <td>Agnes, the shy librarian, stumbled upon an anc...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.579295</td>\n",
       "      <td>63c4dad9-5528-460f-bfe5-43c1ac42e94d</td>\n",
       "      <td>ec9de22a-f810-4fe5-865d-4f4c5f044ac1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A lone astronaut discovers a strange, glowing ...</td>\n",
       "      <td>The rusty drill screeched as it pierced the si...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>cfde001b-7710-47c8-b1b6-b27e4e9d66ed</td>\n",
       "      <td>af733901-045e-436d-b035-4339ecd5d397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults Plot-Driven Story-e726a52b>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def plot_driven_story_generator(inputs: dict):\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=GROQ_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Write a short, plot-driven story (around 100 words) based on this prompt: '{inputs['prompt']}'. Focus on clear events and a resolution.\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "client.evaluate(\n",
    "    plot_driven_story_generator,\n",
    "    data=dataset,\n",
    "    evaluators=[creativity_score_evaluator],\n",
    "    experiment_prefix=\"Plot-Driven Story\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f5a3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from groq import Groq\n",
    "import json \n",
    "\n",
    "groq_client = Groq(api_key=\"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\")\n",
    "\n",
    "GROQ_MODEL = \"gemma2-9b-it\"\n",
    "\n",
    "CREATIVITY_SYSTEM_PROMPT = \"\"\"You are a highly experienced literary critic, tasked with evaluating the creativity and originality of short stories based on a given prompt.\"\"\"\n",
    "\n",
    "CREATIVITY_HUMAN_PROMPT = \"\"\"\n",
    "[The Story Prompt] {prompt}\n",
    "[The Generated Story] {story}\n",
    "\"\"\"\n",
    "\n",
    "class CreativityScore(BaseModel):\n",
    "    score: int = Field(description=\"\"\"A score from 1-5 ranking the creativity and originality of the generated story in response to the prompt, with 1 being unoriginal/generic, and 5 being highly creative and unique.\"\"\")\n",
    "    \n",
    "def creativity_score_evaluator(inputs: dict, outputs: dict) -> list:\n",
    "    completion = groq_client.chat.completions.create(\n",
    "        model=GROQ_MODEL,\n",
    "        messages=[\n",
    "            {   \n",
    "                \"role\": \"system\",\n",
    "                \"content\": CREATIVITY_SYSTEM_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": CREATIVITY_HUMAN_PROMPT.format(\n",
    "                    prompt=inputs[\"prompt\"], \n",
    "                    story=outputs.get(\"output\", \"N/A\"),\n",
    "                )}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    parsed_content = json.loads(completion.choices[0].message.content)\n",
    "    creativity_score = parsed_content.get(\"score\")\n",
    "    \n",
    "    return {\"key\": \"creativity_score\", \"score\": creativity_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e98d579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Two rival knights from different kingdoms meet by chance during a rare cosmic event, forcing them to cooperate.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_example = next(client.list_examples(dataset_id=dataset.id))\n",
    "print(first_example.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b18319d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing 'Story Prompts Dataset for Creativity'.\n",
      "Dataset ID in use: 80f6d3d0-3e0a-404f-8845-b073c7c16f44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langsmith import Client\n",
    "from langsmith.utils import LangSmithNotFoundError \n",
    "import uuid \n",
    "\n",
    "client = Client()\n",
    "\n",
    "\n",
    "story_prompts_data_raw = [\n",
    "    {\"prompt\": \"A lone astronaut discovers a strange, glowing plant on a desolate alien moon.\"},\n",
    "    {\"prompt\": \"A talking cat helps a shy librarian uncover a magical secret hidden in an old book.\"},\n",
    "    {\"prompt\": \"In a future where dreams can be recorded, a detective investigates a dream-heist.\"},\n",
    "    {\"prompt\": \"A baker finds a mysterious ingredient that makes her pastries grant wishes, but with unexpected side effects.\"},\n",
    "    {\"prompt\": \"Two rival knights from different kingdoms meet by chance during a rare cosmic event, forcing them to cooperate.\"}\n",
    "]\n",
    "\n",
    "\n",
    "dataset_name_to_use = \"Story Prompts Dataset for Creativity\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    my_story_dataset = client.read_dataset(dataset_name=dataset_name_to_use)\n",
    "    print(f\"Using existing '{dataset_name_to_use}'.\")\n",
    "  \n",
    "\n",
    "except LangSmithNotFoundError:\n",
    "   \n",
    "    print(f\"Creating new '{dataset_name_to_use}'.\")\n",
    "    my_story_dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name_to_use,\n",
    "        description=\"Dataset for evaluating story generation creativity\",\n",
    "    )\n",
    "    \n",
    "   \n",
    "    for prompt_dict in story_prompts_data_raw:\n",
    "        client.create_example(\n",
    "            dataset_id=my_story_dataset.id,\n",
    "            inputs=prompt_dict, \n",
    "        )\n",
    "    print(f\"Added {len(story_prompts_data_raw)} examples to '{dataset_name_to_use}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during dataset creation/retrieval: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "dataset = my_story_dataset\n",
    "\n",
    "\n",
    "print(f\"Dataset ID in use: {dataset.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5ecc2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAT496",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
